<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on</title><link>https://zenuo.github.io/posts/</link><description>Recent content in Posts on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 14 May 2022 19:23:13 +0800</lastBuildDate><atom:link href="https://zenuo.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Spring StateMachine踩坑</title><link>https://zenuo.github.io/posts/2022/05/14/spring-statemachine%E8%B8%A9%E5%9D%91/</link><pubDate>Sat, 14 May 2022 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2022/05/14/spring-statemachine%E8%B8%A9%E5%9D%91/</guid><description>最近做的客户管理项目，其中客户的开户、合同变更、合同续签功能涉及到走审批（基于公司采购的致远OA系统），业务上有这些需求：
某个确定的功能（比如客户开户）由某些确定的状态、动作组成 某些状态流转取决于审批结果是通过还是拒绝 某个状态允许重新流转 为了实现这些需求，可以简单粗暴if-else硬编码来实现（画面太美），为了代码的可维护性，团队考虑引入某些开源框架来优化，先后调研了工作流框架Flowable、状态机框架Spring StateMachine，基于学习成本和运维成本考虑，决定引入更加轻量的Spring StateMachine。如何快速入手可以参考官网，先介绍一下我们的实践的宏观结构。</description></item><item><title>理解Maven版本号</title><link>https://zenuo.github.io/posts/2022/01/30/%E7%90%86%E8%A7%A3maven%E7%89%88%E6%9C%AC%E5%8F%B7/</link><pubDate>Sun, 30 Jan 2022 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2022/01/30/%E7%90%86%E8%A7%A3maven%E7%89%88%E6%9C%AC%E5%8F%B7/</guid><description>来源Oracle® Fusion Middleware Developing Applications Using Continuous Integration
在使用Maven时，理解如何使用版本号是非常重要的。一个经过深思熟虑（well thought out）的策略可以大大简化你的依赖管理工作量。本文介绍了关于版本号在Maven中如何工作的重要概念。
包含以下三个部分：
Maven版本号如何工作 SNAPSHOT限定符 版本范围引用 1 Maven版本号如何工作 Maven的版本管理方案（scheme）使用以下的标准：
MajorVersion MinorVersion IncrementalVersion BuildNumber Qualifier 例如：
MajorVersion: 1.2.1 MinorVersion: 2.0 IncrementalVersion: 1.2-SNAPSHOT BuildNumber: 1.4.2-12 Qualifier: 1.2-beta-2 具有限定符的版本，旧于没有限定符的（发布版本），例如：1.2-beta-2旧于1.2。
带有不同限定符的相同版本，将会用基础的字符串比较，例如：1.2-beta-2新于1.2-alpha-6。
如果你在项目版本管理方案中没有遵循Maven的版本标准，那么对于版本比较，Maven将整个版本解释为一个简单的字符串。Maven及其核心插件将版本比较用于多项任务，最重要的是用于发布过程。
如果您使用非标准的版本管理方案，Maven发布和版本插件目标可能不会产生预期的结果。因为基本的字符串比较是在非标准的版本上进行的，所以在某些情况下，版本比较会错误地计算版本的顺序。
例如，Maven按以下顺序排列版本列表：
1.0.1.0 1.0.10.1 1.</description></item><item><title>🏎协变、逆变与不变</title><link>https://zenuo.github.io/posts/2020/10/19/%E5%8D%8F%E5%8F%98%E9%80%86%E5%8F%98%E4%B8%8E%E4%B8%8D%E5%8F%98/</link><pubDate>Mon, 19 Oct 2020 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2020/10/19/%E5%8D%8F%E5%8F%98%E9%80%86%E5%8F%98%E4%B8%8E%E4%B8%8D%E5%8F%98/</guid><description>Formal definition 摘自Covariance_and_contravariance_(computer_science)：
Within the type system of a programming language, a typing rule or a type constructor is:
covariant if it preserves the rdering of types (≤), which orders types from more specific to more generic; contravariant if it reverses this ordering; bivariant if both of these apply (i.</description></item><item><title>🧯记一次环境变量导致的中文乱码</title><link>https://zenuo.github.io/posts/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/</link><pubDate>Sun, 14 Jun 2020 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/</guid><description>一、现象 使用本地ssh访问服务器 重启应用 查询主数据商品信息的内容中文乱码 jinfo命令输出file.encoding = ANSI_X3.4-1968 使用Xshell访问服务器 重启应用 jinfo命令输出file.encoding = UTF-8 查询主数据商品信息的内容中文恢复正常 二、为什么乱码 猜想 初步猜想是本地ssh和Xshell的ssh会话的locale会话不同，导致重启后的JVM默认字符集的不同导致了乱码，使用下面的代码片段来验证：
import java.nio.charset.Charset; public class Main { public static void main(String[] args) { System.out.println(System.getProperty(&amp;#34;file.encoding&amp;#34;)); System.out.println(Charset.defaultCharset()); } } 思路：分别使用本地ssh和Xshell访问服务器，查看locale并执行代码片段
使用本地ssh访问：
[服务器 ~]$ locale locale: Cannot set LC_CTYPE to default locale: No such file or directory # 异常信息 locale: Cannot set LC_ALL to default locale: No such file or directory # 异常信息 LANG=en_US.</description></item><item><title>💼命令Command设计模式在设计API时的运用</title><link>https://zenuo.github.io/posts/2020/04/05/%E5%91%BD%E4%BB%A4command%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9C%A8%E8%AE%BE%E8%AE%A1api%E6%97%B6%E7%9A%84%E8%BF%90%E7%94%A8/</link><pubDate>Sun, 05 Apr 2020 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2020/04/05/%E5%91%BD%E4%BB%A4command%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9C%A8%E8%AE%BE%E8%AE%A1api%E6%97%B6%E7%9A%84%E8%BF%90%E7%94%A8/</guid><description>你是否使用过一些类似于这样的API？
命令模式是一种行为设计模式，它可将请求转换为一个包含于请求相关的所有信息的独立对象。改装换让你根据不同的请求将方法参数化，延迟请求执行或将其放入队列中，且能实现可撤销操作。- https://refactoringguru.cn/design-patterns/command</description></item><item><title>🧙🏽‍♂️新人和非技术人员也能看懂的网站应用拓展</title><link>https://zenuo.github.io/posts/2020/01/19/%EF%B8%8F%E6%96%B0%E4%BA%BA%E5%92%8C%E9%9D%9E%E6%8A%80%E6%9C%AF%E4%BA%BA%E5%91%98%E4%B9%9F%E8%83%BD%E7%9C%8B%E6%87%82%E7%9A%84%E7%BD%91%E7%AB%99%E5%BA%94%E7%94%A8%E6%8B%93%E5%B1%95/</link><pubDate>Sun, 19 Jan 2020 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2020/01/19/%EF%B8%8F%E6%96%B0%E4%BA%BA%E5%92%8C%E9%9D%9E%E6%8A%80%E6%9C%AF%E4%BA%BA%E5%91%98%E4%B9%9F%E8%83%BD%E7%9C%8B%E6%87%82%E7%9A%84%E7%BD%91%E7%AB%99%E5%BA%94%E7%94%A8%E6%8B%93%E5%B1%95/</guid><description>翻译自Scaling webapps for newbs &amp;amp; non-techies ，作者Wolfram Hempel
拓展是什么？ 拓展分为横向与纵向；简单来说：
当然，你也可以称之为水平拓展与垂直拓展。
横向拓展（horizontal scaling）：并行地运行很多进程； 纵向拓展（vertical scaling）：在更强大的计算机上运行同样的程序； 今天，很少有人再纵向拓展，因为：
计算机的价格随着性能的提高呈指数增长 一台计算机只能如此之快，这对一台计算机可以垂直扩展的范围施加了严格的限制 多核CPU意味着即使一台计算机都可以有效地并行化-那么为什么不从一开始就并行化呢？ 单个服务器+数据库 这也许是你的后端最开始的样子。一个单独的应用服务器运行着你的业务逻辑，一个数据库保存着数据。事情既简单又好，但是满足更高需求的此设置的唯一方法是在功能更强大的计算机上运行它-不好。
添加一个反向代理 添加一个反向代理是你准备架构的第一步。想一下酒店前台，也许你可以直接将客人带到房间——但是，你真的需要一位中间人来校验一位客人是否被允许进入，是否她的所有文件都齐全并且准备前去一个存在的房间。而且如果房间关闭，您希望有人用友好的声音告诉客人，而不是让他们陷入困境。这就是一个反向代理所做的工作。通常，代理只是一个接收和转发请求的过程。通常，这些请求将从我们的服务器发送到Internet。但是这里的请求来自互联网，需要路由到我们的服务器，因此我们将其称为“反向代理”。
这样的代理可以做这些事：
运行状况检查可确保我们的实际服务器仍在运行 路由将请求转发到正确的端点 身份验证（Authentication）可确保实际上已授予用户访问服务器的权限 防火墙确保用户只能访问他们被允许使用的网络部分 以及更多。
引入一个负载均衡器 反向代理通常可以有负载均衡的功能。负载均衡的概念很简单，想象一下现在有100位用户需要支付，但是你目前只有一台支付服务器，一台支付服务器最多只能支持50位用户支付，你可以同时运行两个支付服务器。
一个负载均衡器的工作就是将请求按照配置的策略分到两个服务器，比如平均分配、按权重分配等等。
增加数据服务器 使用负载均衡器可以将负载分担给多个应用服务器，你看出了目前的问题吗？你可以利用负载均衡将负载分担给成千上万的应用服务器，但是数据库服务器只有一个。那么我们可以用同样的方式来拓展数据库吗？不幸的是不可以。这里的问题是一致性（consistency），我们系统的所有部分都需要就使用的数据达成一致。不一致的数据将导致很多问题，例如订单被处理多次，从同一个账户中重复扣款，以此类推；那么我们如何在确保一致性的同时拓展数据库？
我们可以做的第一件事是将其分为多个部分。一部分专门负责接收和存储数据，其他所有部分负责检索存储的数据。这种解决方案也称为主/从设置与读写分离。此处的假设是读的操作比写的操作次数多。此解决方案的优点是，可以保证一致性，因为数据仅写入单个实例，并从一个实例（从写入到读取）从那里流动。缺点是我们仍然只有一个数据库实例要写入。这对于中小型Web项目是可以的，但是如果您运行Facebook，它就不会这样做。
微服务 到目前为止，我们只处理一台服务器，该服务器可以完成所有工作：处理付款，订单，库存，为网站提供服务，管理用户帐户等等。这不一定是一件坏事-单个服务器意味着较低的复杂性，因此对我们的开发人员而言，头痛更少。但是随着规模的扩大，事情开始变得复杂和低效：
我们服务器的不同部分被不同程度地利用-对于每个用户登录，可能要处理几百次浏览量和要提供的资产，但是所有操作都是由同一台服务器完成的 我们的开发团队会随着我们的应用程序的发展而增长-但是，随着越来越多的开发人员在同一台服务器上工作，他们更有可能踩到彼此的脚趾。 仅拥有一台服务器意味着每当我们要上线新版本时，都必须完成所有工作并进行处理。每当一个团队迅速想要发布更新时，这就会导致危险的相互依赖，而另一团队仅完成了一半的工作。 应对这些挑战的解决方案是一种架构范例，已席卷开发人员：微服务。这个想法很简单-将您的服务器分解为功能单元，并将它们部署为单独的，相互连接的微型服务器。这有很多好处：</description></item><item><title>🧷关于技术写作</title><link>https://zenuo.github.io/posts/2020/01/17/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF%E5%86%99%E4%BD%9C/</link><pubDate>Fri, 17 Jan 2020 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2020/01/17/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF%E5%86%99%E4%BD%9C/</guid><description>翻译自Notes on Technical Writing，作者Marcus Kazmierczak。
在过去的一年中，我处理过WordPress的文档。在冻结发布期间，我开始做出贡献，以帮助开发人员过渡到新平台。我发现编写文档是我的最爱，并且乐于帮助和教育人们。尽管这不是我工作的主要部分，但我仍然在这里和那里找时间继续努力。
这一次，我阅读了有关技术写作和文档的各种资源。这些是我的笔记，既可以帮助我以后记住，又可以作为帮助我考虑现在写的工具。
Principles 在编写文档时，我尝试牢记以下原则：
技术写作的目的是帮助用户尽可能快和高效地完成任务。# People learn by doing, prefer to be shown and not told Get users to their first success quickly 有不止一种类型的文档 保持简单，用平易的语言 Tips Know your audience, know your purpose Put the most important information first Use bullet lists（使用无序符号列表） One idea per paragraph Edit, Edit, Edit（不断改进） Avoid Meta Writing 避免写关于文字的文章，文字没有自己的想法。 活跃的部分是作家和读者。</description></item><item><title>Java内存模型语义</title><link>https://zenuo.github.io/posts/2019/09/01/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E8%AF%AD%E4%B9%89/</link><pubDate>Sun, 01 Sep 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/09/01/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E8%AF%AD%E4%B9%89/</guid><description>翻译自Java Memory Model Pragmatics (transcript)
前言 Java内存模型（Java Memory Model，以后简称JMM）是Java规范中最复杂的部分，至少必须由程序库和运行时开发人员理解。不幸的是，它的措辞是这样的晦涩，以至于它需要一些资深人士为彼此破译它。当然，大多数开发人员并没有按照规定使用JMM规则，而是根据规则制定一些结构，或者更糟糕的是，盲目地复制高级开发人员的结构而不了解其适用性的限制。如果你是一个没有进入核心并发的普通人，你可以通过这篇文章，阅读高级书籍，如“Java Concurrency in Practice”。如果您是对所有这些工作感兴趣的高级人员之一，请继续阅读！
这篇文章是我今年在不同会议上发表的“Java Memory Model Pragmatics”演讲的记录副本，主要是俄语。世界上似乎提供可以容纳这么长时间的讨论的会议数量有限，并且需要在今年的JVMLS上为我的JMM研讨会揭露一些背景阅读，我决定将其转录。
我们将重用很多幻灯片，并且我将尝试基于它们构建叙述。当幻灯片不言自明时，有时候我会跳过没有叙述的。幻灯片有俄语和英语版本。下面的幻灯片是光栅化(rasterized)的，但具有很好的原始分辨率。
我要感谢Brian Goetz，Doug Lea，David Holmes，Sergey Kuksenko，Dmitry Chyuko，Mark Cooper，C.Scott Andreas，Joe Kearney以及其他许多人提供有用的评论和更正。关于最终字段的示例部分包含由Vladimir Sitnikov和Valentin Kovalenko解决的信息，并且是他们关于Final Fields Semantics的更大话题的摘录。
介绍 如果您阅读任何语言规范，您会发现它可以在逻辑上划分为两个相关但不同的部分。首先，一个非常简单的部分是语法，它描述了如何用该语言编写程序。其次，最大的部分是语义，它准确描述了特定语法结构的含义。语言规范通常通过执行程序的抽象机器的行为来描述语义，因此这种语言规范只是一个抽象的机器规范。
当您的语言具有存储（以变量，堆内存等形式）时，抽象机器也具有存储，您必须定义一组有关存储行为的规则。这就是我们所说的内存模型。如果您的语言没有显式存储（例如，您在调用上下文中传递数据），那么您的内存模型非常简单。在存储精通语言中，内存模型似乎回答了一个简单的问题：“特定读取可以观察到什么值？”
在顺序程序中，这似乎是一个空洞的问题：因为你有顺序程序，所以存储到内存中的是按照给定的顺序进行的，很明显读取应该按顺序观察最新的写入。这就是人们通常只为多线程程序遇到内存模型的原因，这个问题变得复杂了。然而，即使在连续的情况下，记忆模型也很重要（尽管它们通常在评估顺序的概念中巧妙地伪装）。
例如，C程序中未定义行为的臭名昭着的例子，它在序列点之间包含一些增量。该程序可以满足给定的断言，但也可以使其失败，或以其他方式召唤鼻子恶魔。有人可能会争辩说，这个程序的结果可能会有所不同，因为增量的评估顺序是不同的，但它不会解释，例如， 12的结果，当两个增量都没有看到另一个的写入值时。这是内存模型的关注点：每个增量应该看到什么值（并且通过扩展，它将存储什么）。
无论哪种方式，当提出实现特定语言的挑战时，我们可以采用两种方式之一：解释或将抽象机器编译到目标硬件。无论如何，解释和编译都通过Futamura Projections连接。 实际应用是解释器和编译器都负责模拟抽象机器。编译器通常被指责搞砸内存模型和多线程程序，但解释器也不能免疫。未能将解释器运行到抽象机器规范可能会导致内存模型违规。最简单的例子：将字段值缓存在解释器中的volatile读取上，您就完成了。这让我们进行了一次有趣的权衡。
编程语言仍然需要智能开发人员的原因是没有超级计算机编译器。 “Hyper”并不夸张：编译器工程中的一些问题是不可判定的，即使在理论上也是不可解决的，更不用说在实践中了。其他有趣的问题在理论上可行，但不实用。因此，为了使实用（优化）编译器成为可能，我们需要在语言中造成一些不便。硬件也是如此，因为（至少对图灵机而言）它只是二氧化硅中的算法。
为了详细说明这个想法，其余的讨论结构如下。
第一部分 Access Atomicity 我们想要什么 在JMM中最容易理解的是访问原子性保证。为了或多或少地严格指定，我们需要引入一些符号。在此幻灯片的示例中，您可以看到包含两列的表。该表示法如下。标题中的所有内容都已经发生：所有变量都已定义，所有初始化的商店都已提交，等等。列是不同的线程。在此示例中，线程1将一些值V2存储到全局变量t中。线程2读取变量，并断言读取值。在这里，我们要确保读取线程仅观察已知值，而不是之间的某些值。
我们有什么 对于理智的编程语言来说，这似乎是一个非常明显的要求：你怎么可能违反这个，为什么？这就是原因。 为了在并发访问下保持原子性，你必须至少让机器指令以给定宽度的操作数操作，否则原子性在指令级别被破坏：如果你需要将访问分成几个子访问，它们可以交错。但即使你有所需的宽度指令，它们仍然可以是非原子的：例如，对于PowerPC来说，2字节和4字节读取的原子性保证是未知的（它们暗示是原子的）。</description></item><item><title>🐚初识布隆过滤器</title><link>https://zenuo.github.io/posts/2019/07/01/%E5%88%9D%E8%AF%86%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</link><pubDate>Mon, 01 Jul 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/07/01/%E5%88%9D%E8%AF%86%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</guid><description>维基百科：布隆过滤器（英语：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。
本文翻译自Probabilistic Data structures: Bloom filter
如果您有一个玻璃保护的书架，这将保护您的书籍免受灰尘和昆虫的侵害，但在您需要时，您将花费更多时间来阅读书籍。因为你首先需要滑动或打开玻璃然后才能拿到书。另一方面，如果它是一个开放的书架，这将使您更快地访问，但您将失去保护。同样，如果您按照其姓名的字典顺序组织图书，如果您知道图书的名称，则可以轻松搜索图书。但是，如果你的书架上有不同大小的盒子，你可以根据它们的大小来整理你的书籍，它看起来不错，但是你能赶紧找到一本书吗？我不这么认为。
数据结构和书架一样，您可以在其中组织数据。不同的数据结构将为您提供不同的设施和好处。要正确使用数据结构的功能和可访问性，您需要知道使用数据结构的权衡。
当主流数据结构如List，Map，Set，Tree等等主要用于实现关于数据是否存在的某些结果时，可能伴随着它们的出现次数等，概率数据结构（Probabilistic Data structures）将为您提供内存效率更快的结果是提供可能的结果而不是某个结果。现在使用这样的数据结构可能看起来不太直观，但我会在本文中试图说服这些类型的数据结构具有特定的用例，并且您可能会发现它们在某些情况下很有用。
在这篇文章中，我将讨论一种称为“布隆过滤器”的最流行的概率数据结构。
布隆过滤器 你知道哈希表是如何工作的吗？在简单数组或列表中插入新数据时，将插入此数据的索引不是从要插入的值确定的。这意味着&amp;rsquo;key(index)&amp;lsquo;和&amp;rsquo;value(data)&amp;lsquo;之间没有直接关系。因此，如果需要在数组中搜索值，则必须在所有索引中进行搜索。现在，在哈希表中，您可以通过散列值来确定键或索引。然后将此值放在列表中的该索引中。这意味着key是根据value确定的，每次你需要检查列表中是否存在该值时，只需对值进行散列并搜索该键即可。它非常快，并且需要以大O表示法进行O(1)搜索时间。
现在，让我们考虑一下你有一个庞大的弱密码列表，它存储在一些远程服务器上。由于尺寸的原因，无法在内存中一次加载它们。每次用户输入他/她的密码时，你想检查它是否是弱密码之一，如果是，你想给他/她一个警告，把它改成更强的密码。你能做什么？由于您已经拥有弱密码列表，您可以将它们存储在哈希表或类似的东西中，并且每次要匹配时，如果给定的密码有任何匹配，您可以检查它。匹配可能很快，但在磁盘上或通过远程服务器上的网络进行搜索的成本会使其变慢。不要忘记，您需要为每个用户提供的每个密码执行此操作。我们如何降低成本？
好吧，Bloom过滤器可以帮助我们。怎么样？在解释布隆过滤器的工作原理后，我将回答这个问题。
根据定义，Bloom过滤器可以检查值是“可能在集合中”还是“绝对不在集合中”。 可能和绝对不之间的细微差别在这里非常重要。这个“可能在集合中”正是它被称为概率的原因。使用智能词语意味着可能存在误报（false positive）（可能存在错误地认为该元素是阳性的情况）但是假阴性是不可能的。不要急躁，我们很快就会解释它究竟意味着什么。
布隆过滤器基本上由长度为m的位向量或位列表（仅包含0或1位值的列表）组成，最初所有值都设置为0，如下所示：
要将项添加到bloom过滤器，我们将其提供给k个不同的哈希函数，并在结果位置将这些位设置为1。如您所见，在哈希表中我们将使用单个哈希函数，因此只获得一个索引作为输出。但是在布隆过滤器的情况下，我们将使用多个哈希函数，这将为我们提供多个索引。
正如您在上面的示例中所看到的，对于给定的输入&amp;rsquo;geeks&amp;rsquo;，我们的3个散列函数将给出3个不同的输出 -1,4和7，我们已经标记了它们。
对于另一个输入&amp;rsquo;nerd&amp;rsquo;，哈希函数给出了3,4和5.您可能已经注意到索引'4&amp;rsquo;已经被先前的&amp;rsquo;geeks&amp;rsquo;输入标记。坚持你的想法，这一点很有趣，我们很快就会讨论它。
我们已经用两个输入填充了我们的位向量，现在我们可以检查它存在的值。我们怎么做？ 简单。就像我们在散列表中完成它一样。我们将使用我们的3个哈希函数对搜索输入进行哈希处理，并查看结果索引保持的内容。
因此，搜索&amp;rsquo;cat'，我们的哈希函数这次给我们1,3和7。我们可以看到所有索引都已标记为1.这意味着我们可以说，“也许&amp;rsquo;cat&amp;rsquo;已经插入我们的列表中”。但事实并非如此。出了什么问题？
实际上，没有出错。问题是，这是误报的情况。布隆过滤器告诉我们似乎之前可能插入了&amp;rsquo;cat'，因为索引应该已经被&amp;rsquo;cat&amp;rsquo;标记（尽管是其他不同的数据）。
那么，如果是这样的话，它有什么用呢？那么，让我们考虑一下&amp;rsquo;cat&amp;rsquo;是否会给我们输出1,6,7而不是1,3,7，那么会发生什么呢？我们可以看到，在3个索引中，6为'0'，这意味着它没有被任何先前的输入标记。这意味着很明显&amp;rsquo;猫&amp;rsquo;从未插入过，如果是的话，那么6就没有机会成为'0'，对吗？这就是如果数据不在列表中，布隆过滤器可以“肯定”地告诉它。
所以，简而言之：
如果我们搜索一个值并看到该值的任何散列索引为'0'，那么该值肯定不在列表中。 如果所有散列索引都为“1”，则“可能”搜索的值在列表中。 它开始有意义吗？有点可能吗？
很好，现在，回到我们之前谈到的&amp;rsquo;密码&amp;rsquo;示例。如果我们用这种类型的布隆过滤器实现我们的弱密码检查，你可以看到，最初，我们会用我们的密码列表标记我们的布隆过滤器，这将给我们一个位向量，其中一些索引标记为'1&amp;rsquo;而其他索引因为布隆过滤器的大小不会很大并且是固定大小，所以如果需要，它可以很容易地存储在存储器中，也可以存储在客户端。这就是为什么布隆过滤器非常节省空间的原因。在散列表需要基于输入数据的任意大小的情况下，布隆过滤器可以在固定大小下很好地工作。
因此，每次用户输入密码时，我们都会将其提供给我们的哈希函数，并根据我们的位向量进行检查。如果密码足够强，布隆过滤器将向我们显示密码肯定不在“弱密码列表”中，我们不必再进行任何查询。但是如果密码看起来很弱并且给我们一个“肯定的”（可能是误报）结果，我们会将它发送到我们的服务器并检查我们的实际列表以确认。
如您所见，大多数时候我们甚至不需要向我们的服务器发出请求或从磁盘读取以检查列表，这将显着提高应用程序的速度。如果我们不想在客户端存储位向量，我们仍然可以将其加载到服务器内存中，这至少可以节省一些磁盘查找时间。还要考虑一下，如果您的布隆过滤器误报率为1％（我们稍后会详细讨论错误率），这意味着在服务器或磁盘的昂贵往返中，只有1％的查询将是以虚假结果返回，其他99％不会徒劳无功。不错。
布隆过滤器操作 基本布隆过滤器支持两种操作：测试和添加。测试用于检查给定元素是否在集合中。添加只是向集合添加元素。
现在问题来了，根据我们到目前为止所讨论的内容，是否可以从布隆过滤器中删除项目？如果是，那怎么样？
休息2分钟，考虑一下解决方案。
现在我们要从中删除&amp;rsquo;geeks'。因此，如果我们从位向量中移除1,4,7，因为它们被&amp;rsquo;geeks&amp;rsquo;标记，并将它们转换为'0'，会发生什么？您可以很容易地看到，下次如果我们搜索&amp;rsquo;nerd'，因为索引'4&amp;rsquo;将显示'0'，它肯定会告诉我们&amp;rsquo;nerd&amp;rsquo;不在列表中，尽管它实际上是。这意味着在不引入假阴性的情况下无法移除。
那么，解决方案是什么？
解决方案是我们不能在这个简单的布隆过滤器中支持删除操作。但是如果我们真的需要具有移除功能，我们可以使用称为计数布隆过滤器的布隆过滤器的变体。这个想法很简单。我们将存储一个整数值，而不是存储单个位值，然后我们的位向量将是一个整数向量。这将增加尺寸并增加空间，为我们提供删除功能。我们不会在插入值时将位值标记为“1”，而是将整数值递增1.要检查元素是否存在，请检查散列元素后的相应索引是否大于0。</description></item><item><title>如何实现分布式锁</title><link>https://zenuo.github.io/posts/2019/06/23/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</link><pubDate>Sun, 23 Jun 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/06/23/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</guid><description>翻译自How to do distributed locking
作为本书的一部分，我在Redis发现了一种名为Redlock的算法，该算法声称在Redis上实现容错分布式锁（或者更确切地说，租用[1]），并且页面要求来自分布式系统地人的反馈。这个算法本能在我的脑海里引发了一些警钟，所以我花了些时间思考它，并写下这些笔记。
由于已经有超过10个独立的Redlock实现，我们不知道谁已经依赖这个算法，我认为值得公开分享我的笔记。我不会涉及Redis的其他方面，其中一些已经在其他地方被评论过。
在我详细介绍Redlock之前，请允许我说我非常喜欢Redis，过去我已成功将它用于生产中。我认为它非常适合您希望在服务器之间共享一些瞬态，近似，快速变化的数据的情况，以及如果您因某种原因偶尔丢失数据并不是什么大不了的地方。例如，一个好的用例是维护每个IP地址的请求计数器（用于速率限制）和每个用户ID的不同IP地址集（用于滥用检测）。
然而，Redis已经逐渐进入数据管理领域，这些领域具有更强的一致性和耐用性预期 - 这让我担心，因为这不是Redis的设计目标。 可以说，分布式锁定是其中一个领域。 让我们更详细地研究它。可以说，分布式锁定是其中一个领域。 让我们更详细地研究它。
你将锁定用于何处 锁定的目的是确保在可能尝试执行相同工作的多个节点中，只有一个实际执行它（至少一次只执行一次）。这项工作可能是将一些数据写入共享存储系统，执行某些计算，调用某些外部API等。 在较高的层次上，有两个原因可能导致您在分布式应用程序中需要锁定：效率或正确性。为了区分这些情况，您可以询问如果锁定失败会发生什么：
效率：锁定可以避免不必要地执行相同的工作两次（例如，一些昂贵的计算）。 如果锁定失败并且两个节点最终完成相同的工作，结果是成本略有增加（最终为AWS支付的费用比您原本要多5美分）或稍有不便（例如用户最终） 两次收到相同的电子邮件通知）。
正确性：采取锁定可防止并发进程踩到彼此的脚趾并弄乱系统状态。 如果锁定失败并且两个节点同时处理同一条数据，则结果是文件损坏，数据丢失，永久性不一致，给予患者的药物剂量错误或其他一些严重问题。
两者都是想要锁定的有效案例，但是你需要非常清楚你要处理的两个中的哪一个。
我将争辩说，如果您仅仅为了提高效率而使用锁，则不必承担Redlock的成本和复杂性，运行5台Redis服务器并检查大多数锁以获取锁。 您最好只使用一个Redis实例，可能在主要崩溃的情况下使用异步复制到辅助实例。
如果您使用单个Redis实例，当然如果Redis节点上的电源突然断电或者出现其他问题，您将丢弃一些锁。 但是如果你只是使用锁作为效率优化，并且崩溃不会经常发生，那没什么大不了的。 这个“没什么大不了的”情景是Redis闪耀的地方。 至少如果您依赖于单个Redis实例，那么每个看系统的人都很清楚锁是近似的，并且仅用于非关键目的。
另一方面，具有5个副本和多数表决权的Redlock算法乍一看，好像它适用于锁定对正确性很重要的情况。 我将在以下各节中论证它不适合这个目的。 对于本文的其余部分，我们将假设您的锁对于正确性很重要，并且如果两个不同的节点同时认为它们持有相同的锁，那么这是一个严重的错误。
使用锁保护资源 让我们暂时搁置Redlock的细节，并讨论如何使用分布式锁（与所使用的特定锁定算法无关）。 重要的是要记住，分布式系统中的锁不像多线程应用程序中的互斥锁。 这是一个更复杂的野兽，因为不同的节点和网络都可以以各种方式独立地失败。
例如，假设您有一个应用程序，其中客户端需要更新共享存储中的文件（例如HDFS或S3）。 客户端首先获取锁，然后读取文件，进行一些更改，将修改后的文件写回，最后释放锁。 该锁防止两个客户端同时执行此读 - 修改 - 写周期，这将导致更新丢失。 代码可能如下所示：</description></item><item><title>缓存穿透、缓存击穿与缓存雪崩</title><link>https://zenuo.github.io/posts/2019/05/22/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E4%B8%8E%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/</link><pubDate>Wed, 22 May 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/05/22/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E4%B8%8E%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/</guid><description>翻译自3 major problems and solutions in the cache world
当前的IO设备远远不能满足互联网应用程序的大量读写请求。然后有一个缓存，使用内存的高速读写性能来应对大量的查询请求。但是，内存资源非常宝贵，将全部数据存储在内存中显然是不切实际的。因此，当前内存和IO的组合，内存只存储热点数据，而IO设备存储全部数据。缓存的设计包含很多技巧，不正确的设计会导致严重的后果。
1 缓存穿透（Cache penetration） 在大多数互联网应用程序中：
当业务系统发起某个查询请求时，它首先确定数据是否存在于缓存中; 如果有缓存，则直接返回数据; 如果缓存不存在，请再次查询数据库并返回数据。 在理解了上述过程之后，我们来谈谈缓存穿透。
1.1 是什么 当业务系统发起查询时，根据上面的过程，查询将首先进入缓存，因为缓存不存在，然后转到数据库进行查询。由于数据根本不存在，因此数据库也返回**null**。这是缓存穿透。
总结一下：业务系统访问根本不存在的数据称为缓存穿透。
1.2 危险是什么 如果查询请求中不存在大量数据，那么这些大量请求将落入数据库，数据库压力将急剧增加，这可能导致系统崩溃。 （你必须知道当前业务系统中最脆弱的是IO，有点它会在压力下崩溃，所以我们必须想办法保护它）。
1.3 为什么会发生 恶意攻击故意创建大量不存在的数据来请求我们的服务。由于缓存中不存在这些数据，因此大量请求会进入数据库，这可能导致数据库崩溃。 代码逻辑错误。这是程序员的锅，无话可说，必须在开发中避免！ 1.4 如何避免 以下是防止的两种方法：
1.4.1 缓存空数据 缓存穿透的原因是缓存中没有用于存储这些空数据的密钥，导致所有这些请求都到达数据库。
然后，我们可以稍微修改业务系统的代码，并将具有空数据库查询结果的密钥存储在缓存中。当再次发生对密钥的查询请求时，缓存直接返回**null**而不查询数据库。
1.4.2 布隆过滤器（BloomFilter） 它需要在缓存之前添加一个屏障，它存储当前数据库中存在的所有key。
当业务系统有查询请求时，首先转到BloomFilter以检查key是否存在。
如果它不存在，则表示数据库中不存在数据，因此不应检查缓存，并直接返回**null**。 如果存在，继续执行后续过程，首先查询缓存，如果没有缓存，则查询数据库。 1.</description></item><item><title>「勾勾」一个基于谷歌的搜索工具</title><link>https://zenuo.github.io/posts/2019/05/11/%E5%8B%BE%E5%8B%BE%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E%E8%B0%B7%E6%AD%8C%E7%9A%84%E6%90%9C%E7%B4%A2%E5%B7%A5%E5%85%B7/</link><pubDate>Sat, 11 May 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/05/11/%E5%8B%BE%E5%8B%BE%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E%E8%B0%B7%E6%AD%8C%E7%9A%84%E6%90%9C%E7%B4%A2%E5%B7%A5%E5%85%B7/</guid><description>是什么 「勾勾」是一个搜索工具，搜索结果基于谷歌，致力于「安全和简洁」的搜索体验。
安全 「勾勾」是一个在用户与谷歌之间的代理，谷歌无法得知用户的隐私（如UserAgent、Cookie等），也无法跟踪用户的结果点击
部署简单，基于JDK 11，仅需一台处于可以访问谷歌的网络的主机即可
简洁 精简（丑陋）到极致的Web前端 提供Web API，轻松地自定义搜索前端 如何使用 本程序通过网页、命令行和Web API三种方式提供服务。
网页 可访问实例体验
首页截图：
搜索页面截图：
命令行 请到Release页面下载可执行程序，并重命名为gogo-cli，放置到PATH路径下
$ gogo-cli github 1 截图如下：
Web API 搜索 $ curl -X GET -k &amp;#34;https://176.122.157.231:5000/api/search?q=github&amp;amp;p=1&amp;#34; { &amp;#34;key&amp;#34;: &amp;#34;github&amp;#34;, &amp;#34;page&amp;#34;: 1, &amp;#34;amount&amp;#34;: 223000000, &amp;#34;elapsed&amp;#34;: 0.</description></item><item><title>一个成功的Git分支模型</title><link>https://zenuo.github.io/posts/2019/05/09/%E4%B8%80%E4%B8%AA%E6%88%90%E5%8A%9F%E7%9A%84git%E5%88%86%E6%94%AF%E6%A8%A1%E5%9E%8B/</link><pubDate>Thu, 09 May 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/05/09/%E4%B8%80%E4%B8%AA%E6%88%90%E5%8A%9F%E7%9A%84git%E5%88%86%E6%94%AF%E6%A8%A1%E5%9E%8B/</guid><description>翻译自A successful Git branching model
这篇文章介绍了一种开发模型，适用于工作或私人项目，只讨论分支策略和发布管理，不会讨论任何项目的细节。
为何是Git？ 你可以在这篇文章上查看关于Git与集中式源代码控制系统（centralized source code control systems）相比较的优缺点，讨论比较激烈。作为一个开发者，我更喜欢Git，而不是其他的所有工具。Git改变了开发者对于合并与分支的思考方式。从我之前所在的经典的CVS/Subversion世界来看，合并/分支一直被视为可怕的事情，每隔一段时间就会做一次，要小心合并冲突，它们会吃了你。
但在Git的世界里，这些动作极其廉价和简单，而且它们被视为日常工作流的核心部分。在CVS/Subversion的书中，首次介绍分支与合并是在最后一章（对于高级用户），然而Git的书中是在第三章（基础）。
由于其天生的简单性和重复性，分支和合并不再是一件令人害怕的事情。版本控制工具应该比其他任何东西更有助于分支/合并。
关于工具已经谈得足够了，让我们进入开发模型的讨论。我将介绍的模型基本上只是每个团队开发成员必须遵循的一组程序才能进入被管理的软件开发过程。
分散但集中 一个中心的真实的仓库，是我们用来与当前分支模型协作的。注：这个仓库仅仅被视为中心的一个，我们所用用户将其称作origin。
每个开发者从origin拉取（pull）和推送（push）。但是除了集中地推送拉取的关系，每个开发中也会从其他同事拉取变更来组成子团队，例如这在将工作进度永久推送到origin之前，两个或更多开发者协作开发一个新的功能很有用。在上图中，有三个子团队，分别是alice和bob、alice和david、david和clair。
从技术上讲，这意味着Alice定义了一个名为bob的远程（remote），指向Bob的仓库，反之亦然。
主要分支 在核心部分，这个开发模型极大程度上受下面的模型启发。中央仓库含有了两个具有无限生命时间的分支：
master develop origin的master分支应该对于所有Git用户都很熟悉。与master平行地，还存在一个称为develop的分支。
我们称origin/master是主要的分支，因为其HEAD的源代码总是在生产就绪状态。
我们称origin/develop是主要的分支，因为其HEAD的源代码总是在下一个发布版本的最新交付的开发变更。有时也被称作集成分支，是所有自动夜间构建的来源。
当develop分支的源代码达到稳定并且发布就绪的状态时，所有的变更应该被合并回到master，并被标记上一个发布编号。后面我们会讨论实现细节。
因此。每次将变更合并回master时，根据定义，这是i一个新的生产版本，对此应该非常严格。可以使用Git钩子脚本在每次有master提交时自动构建和推出软件到我们的生产服务器。
支持分支 在主分支master和develop之后，我们的开发模型还会用到一系列支持分支来用于团队成员之间的平行开发，使跟踪功能、准备生产发布和快速修复生产环境问题等。与主分支不同，这些分支通常的生命周期的有限的，因为它们最后会被删除。
我们用到的不同种类的分支是：
Feature分支 Release分支 Hotfix分支 这些分支的没一个都有特定的目的，并且必须遵守关于哪些分支必须是它们的合并目标的严格规则。我们下面开始讨论它们。
从技术角度来看，这些分支不是特殊的，分支类型取决与我们如何使用它们，它们是普通的Git分支。
Feature分支 可以从develop分支创建，可以合并到develop，分支命名惯例：除了master、develop、release-*或者hotfix-*之外的名称。
Feature分支（或者有时被称作Topic分支）通常备用做开发近期或者远期新的特征。当开始开发一个特征时，可能还不知道此特征将会合并到哪一个发布。一个feature分支的本质是在其对应特征开发过程中存在，但最终会被合并回develop（确定地将该特征添加到近期的发布中）或者被忽略（比如一个令人失望的实验的情况）。
创建一个feature分支 当开始一个新特征时，从develop分支创建：
$ git checkout -b myfeature develop Switched to a new branch &amp;#34;myfeature&amp;#34; 将一个完成的feature加入到develop $ git checkout develop Switched to branch &amp;#39;develop&amp;#39; $ git merge --no-ff myfeature Updating ea1b82a.</description></item><item><title>Git架构</title><link>https://zenuo.github.io/posts/2019/05/05/git%E6%9E%B6%E6%9E%84/</link><pubDate>Sun, 05 May 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/05/05/git%E6%9E%B6%E6%9E%84/</guid><description>翻译自The Architecture of Open Source Applications (Volume 2): Git
简述 Git允许许多协作者使用对等的存储库网络维护数字化工作体（通常但不限于代码），支持分布式工作流，允许工作体最终的交汇或暂时的分歧。本章将展示Git的各个方面如何实现，以及与其他版本控制系统（VCS）的区别。
来源 为了更好地理解Git的设计理念，有助于理解在Linux内核社区中启动Git项目的环境。
相较于当时的其他商业软件项目，Linux内核是不寻常的，因为提交者数量众多，贡献者参与度和现有代码库知识的差异很大。多年来，内核一直通过tarball和补丁进行维护，核心开发社区努力寻找满足其大部分需求的VCS。
Git是一个开源项目，源于2005年的需求和挫折。当时的Linux内行人代码库由两个VCS（BitKeeper和CVS）由不同的核心开发者管理。BitKeeper提供了与当前流行的开源VCS提供的VCS历史谱系不同的视图。
BitKeeper的制造商BitMover宣布将取消一些核心Linux内核开发人员的许可后几天，Linus Torvalds开始急于开发Git。他首先编写了一系列脚本来帮助他管理电子邮件补丁，以便一个接一个地应用。这个初始脚本集合的目的是能够快速中止合并，以便维护者可以修改code-mid-patch-stream中的代码库以手动合并，然后继续合并后续补丁。
从一开始，Torvalds对Git有一个哲学目标——成为反CVS加三个可用性设计目标：
支持分布式工作流，类似于BitKeeper启用的工作流。 提供防范内容损坏的保护措施。 提供高性能。 这些设计目标已在一定程度上完成和维护，正如我将试图通过剖析Git使用有向无环图（DAG）进行内容存储，头部参考指针，对象模型表示和远程协议来展示;最后Git如何跟踪树的合并。
尽管BitKeeper影响了Git的原始设计，但它以完全不同的方式实现，并允许更多的分布式加上仅限本地的工作流，这是BitKeeper无法实现的。 Monotone是一个开源的分布式VCS，始于2003年，可能是Git早期开发过程中的另一个灵感来源。
分布式版本控制系统提供了极大的工作流程灵活性，通常以简单性为代价分布式模型的特定优势包括：
为协作者提供脱机工作和递增提交的能力。 允许协作者确定他/她的工作何时可以分享。 在离线时提供协作者对存储库历史记录的访问权限。 允许将托管作业发布到多个存储库，可能会显示不同的分支或更改粒度。 在Git项目启动的时候，启动了另外三个开源分布式VCS项目。 （其中之一，Mercurial，在开源应用程序架构的第1卷中进行了讨论。）所有这些dVCS工具都提供了稍微不同的方法来实现高度灵活的工作流程，这些工作流程集中了VCS，直到它们无法直接处理。注意：Subversion有一个名为SVK的扩展，由不同的开发人员维护，以支持服务器到服务器的同步。
今天流行且积极维护的开源dVCS项目包括Bazaar，Darcs，Fossil，Git，Mercurial和Veracity。
版本控制系统设计 现在是退一步看看Git的替代VCS解决方案的好时机。了解他们的差异将使我们能够探索在开发Git时面临的架构选择。
版本控制系统通常有三个核心功能要求，即：
内容存储 跟踪内容更改（包括合并元数据的历史记录） 与协作者分发内容和历史记录 注意：上述第三个要求不是所有VCS的功能要求。
内容存储 用于在VCS世界中存储内容的最常见设计选择是基于增量的变更集，或者具有有向无环图（DAG）内容表示。
基于Delta的变更集封装了扁平内容的两个版本之间的差异，以及一些元数据。将内容表示为有向非循环图包含形成层次结构的对象，该层次结构将内容的文件系统树镜像为提交的快照（尽可能重用树内未更改的对象）。 Git使用不同类型的对象将内容存储为有向非循环图。本章后面的“对象数据库”部分描述了可以在Git存储库中形成DAG的不同类型的对象。</description></item><item><title>关于Java语言的finally语句</title><link>https://zenuo.github.io/posts/2019/05/05/%E5%85%B3%E4%BA%8Ejava%E8%AF%AD%E8%A8%80%E7%9A%84finally%E8%AF%AD%E5%8F%A5/</link><pubDate>Sun, 05 May 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/05/05/%E5%85%B3%E4%BA%8Ejava%E8%AF%AD%E8%A8%80%E7%9A%84finally%E8%AF%AD%E5%8F%A5/</guid><description>是否一定执行、执行时机 一切要从这道题目说起：
Java语言中的finally语句（块）一定会被执行吗？是在try语句返回之前还是之后执行？
由于对这个问题的一知半解，当时只回答了前半个问题是的，一定会执行，没有回答后半个问题；笔试结束后查资料&amp;hellip;才发现事情没那么简单🤯
诚然，我的回答是错误的，以下两种情况的finally语句不会被执行：
try语句没有被执行；也说明了finally语句被执行的必要非充分条件是对应try语句被执行 try语句中有停止JVM的语句； 后半个问题的答案是之前，即在try语句返回之前执行，可通过一个简单的例子来说明：
jshell&amp;gt; String test1() { ...&amp;gt; System.out.println(&amp;quot;return statement&amp;quot;); ...&amp;gt; ...&amp;gt; return &amp;quot;after return&amp;quot;; ...&amp;gt; } | created method test1() jshell&amp;gt; String test2() { ...&amp;gt; try { ...&amp;gt; System.out.println(&amp;quot;try block&amp;quot;); ...&amp;gt; ...&amp;gt; return test1(); ...&amp;gt; } finally { ...&amp;gt; System.out.println(&amp;quot;finally block&amp;quot;); ...&amp;gt; } .</description></item><item><title>可扩展的事件多路复用：epoll与kqueue</title><link>https://zenuo.github.io/posts/2019/05/01/%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8epoll%E4%B8%8Ekqueue/</link><pubDate>Wed, 01 May 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/05/01/%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8epoll%E4%B8%8Ekqueue/</guid><description>翻译自Scalable Event Multiplexing: epoll vs. kqueue
我比BSD更喜欢Linux，但我确实想在Linux中使用BSD的**kqueue**功能。
什么是事件多路复用（event multiplexing） 假设您有一个简单的Web服务器，并且当前有两个打开的连接（套接字）。当服务器从任一连接收到HTTP请求时，它应该向客户端发送HTTP响应。但是你不知道两个客户端中的哪一个会先发送消息，何时发送消息。BSD Socket API的阻塞行为意味着如果在一个连接上调用recv()，您将无法响应另一个连接上的请求。这是您需要**I/O多路复用（I/O multiplexing）**的地方。
I/O复用的一种简单方法是为每个连接提供一个进程/线程，以便在一个连接中阻塞不会影响其他连接。通过这种方式，您可以有效地将所有毛茸茸的调度/多路复用问题委托给OS内核。这种多线程架构带来（可以说）高成本。维护大量线程对于内核来说并非易事。为每个连接设置单独的堆栈会增加内存占用，从而降低CPU**缓存局部性（cache locality）**。
如何在没有线程连接的情况下实现I / O复用？您可以使用非阻塞套接字操作为每个连接执行繁忙等待轮询，但这太浪费了。我们需要知道的是哪个套接字准备好了。因此，操作系统内核在您的应用程序和内核之间提供了一个单独的通道，此通道会在您的某些套接字准备就绪时通知。这就是**select()/poll()的工作原理，基于就绪模型（readiness model）**。
回顾：select() select()和poll()在它们的工作方式上非常相似。让我快速回顾一下select()的样子。
select(int nfds, fd_set *r, fd_set *w, fd_set *e, struct timeval *timeout) 使用**select()，您的应用程序需要提供三个兴趣集（interest sets）r，w和e**。每个集都表示为文件描述符的位图。例如，如果您对从文件描述符6中读取感兴趣，则将**r的第六位设置为1。这个调用是阻塞的，直到感兴趣集中的一个或多个文件描述符准备就绪，这样您就可以对这些文件描述符执行没有阻塞的操作**。返回后，内核将覆盖位图以指定哪些文件描述符已准备就绪。
在可扩展性方面，我们可以找到四个问题：
这些位图的大小是固定的（FD_SETSIZE，通常为**1024**）。但是，有一些方法可以解决这个限制。 由于位图被内核覆盖，用户应用程序应该为每个调用重新填充兴趣集。 用户应用程序和内核应扫描每个调用的整个位图，以确定哪些文件描述符属于兴趣集和结果集。这对于结果集来说尤其低效，因为它们可能非常稀疏（即，在给定时间只有少数文件描述符准备好）。 内核应迭代整个兴趣集，以找出哪些文件描述符已准备好，再次针对每个调用。如果它们都没有准备就绪，则内核再次迭代以为每个套接字注册内部事件处理程序。 回顾：poll() poll()旨在解决其中的一些问题。
poll(struct pollfd *fds, int nfds, int timeout) struct pollfd { int fd; short events; short revents; } **poll()**不依赖于位图，而是依赖于文件描述符数组（因此解决了问题＃1）。通过为感兴趣（事件）和结果（revents）提供单独的字段，如果用户应用程序正确维护并重新使用该数组，则问题＃2也会得到解决。如果轮询分离数组而不是字段，问题＃3可能已经修复。最后一个问题是固有的，不可避免的，因为select()和poll()都是无状态的；内核不会在内部维护兴趣集。</description></item><item><title>事务隔离等级提交读与可重复读的区别</title><link>https://zenuo.github.io/posts/2019/04/20/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%AD%89%E7%BA%A7%E6%8F%90%E4%BA%A4%E8%AF%BB%E4%B8%8E%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E7%9A%84%E5%8C%BA%E5%88%AB/</link><pubDate>Sat, 20 Apr 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/04/20/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%AD%89%E7%BA%A7%E6%8F%90%E4%BA%A4%E8%AF%BB%E4%B8%8E%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E7%9A%84%E5%8C%BA%E5%88%AB/</guid><description>翻译自Differences between READ-COMMITTED and REPEATABLE-READ transaction isolation levels
作为Percona的讲师，我有时会被问及已提交读和可重复读事务隔离级别之间的区别，它们存在一些差异，但都与锁定有关。
额外锁定 (非间隙锁定) 请记住，InnoDB实际上锁定了索引条目（index entries），而不是行（rows），这很重要。在执行语句期间，InnoDB必须锁定它遍历的索引中的每个条目，以查找它正在修改的行。他必须这样做以防止死锁并保持隔离级别。
若执行一句未被良好索引的UPDATE语句，则会锁定很多行：
updateemployeessetstore_id=0wherestore_id=1;---TRANSACTION 1EAB04, ACTIVE 7 sec -- 633 lock struct(s), &amp;lt;strong&amp;gt;heap size 96696&amp;lt;/strong&amp;gt;, 218786 row lock(s), undo log entries 1 -- MySQL thread id 4, OS thread handle 0x7f8dfc35d700, query id 47 localhost root -- show engine innodb status 在employee表中，列store_id没有被索引。请注意，UPDATE已经完成运行（我们现在正在运行SHOW ENGINE &amp;hellip;）但是我们持有218786个行锁并且只有一个撤销条目（undo entry）。这意味着只有一行被更改，但我们仍然持有额外的锁。堆大小表示已为锁分配的内存量。</description></item><item><title>实践java.util.concurrent.TransferQueue</title><link>https://zenuo.github.io/posts/2019/03/10/%E5%AE%9E%E8%B7%B5java.util.concurrent.transferqueue/</link><pubDate>Sun, 10 Mar 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/03/10/%E5%AE%9E%E8%B7%B5java.util.concurrent.transferqueue/</guid><description>综述 java.util.concurrent.TransferQueue是Java Collections Framework的成员之一，允许我们根据生产者-消费者模式创建程序，并协调从生产者传递给消费者的消息，其JDK内的实现是java.util.concurrent.LinkedTransferQueue。
实现实际上类似于BlockingQueue - 但是为我们提供了实现backpressure形式的新功能。这意味着，当生产者使用transfer()方法向使用者发送消息时，生产者将保持阻塞状态，直到消息被消耗为止（tryTransfer()是非阻塞的）。
可以通过hasWaitingConsumer()查询是否有任何消费者在等待，与peek()操作相反。
一个生产者——无消费者 首先，设计一个生产者来测试transfer()方法 - 预期是生产者将被阻塞，直到消费者使用take()方法从队列接收消息。
class Producer implements Runnable { private TransferQueue&amp;lt;String&amp;gt; transferQueue; private String name; private Integer numberOfMessagesToProduce; public AtomicInteger numberOfProducedMessages = new AtomicInteger(); @Override public void run() { for (int i = 0; i &amp;lt; numberOfMessagesToProduce; i++) { try { boolean added = transferQueue.</description></item><item><title>Nginx架构</title><link>https://zenuo.github.io/posts/2019/01/31/nginx%E6%9E%B6%E6%9E%84/</link><pubDate>Thu, 31 Jan 2019 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2019/01/31/nginx%E6%9E%B6%E6%9E%84/</guid><description>翻译自The Architecture of Open Source Applications (Volume 2): nginx
nginx（读作&amp;quot;engine x&amp;quot;）是由Igor Sysoev（一名俄罗斯软件工程师）开发的一款自由开源的Web服务器程序。自2004年公开发布以来，nginx一直专注于高性能、高并发行和低内存使用。负载均衡、缓存和访问及带宽控制等Web服务器功能之上的其他功能，以及有效集成各种应用程序的能力，都帮助使nginx成为现代架构的不错选择。当前nginx是互联网上第二受欢迎的开源Web服务器。
1 为何高并发性是重要的 如今，互联网如此广泛和无处不在，很难想象它不是十年前我们所知道的那样。从简单的HTML生成可点击文本，基于NCSA，然后是Apache Web服务器，到全球超过20亿用户使用的在线通信媒体，它已经有了长足发展。随着永久连接的个人电脑、移动设备和平板电脑的激增，互联网领域正在迅速变化，整个经济已经成为数字连线。在线服务变得更加精细，明显偏向即使可用的实时信息和娱乐。运行在线业务的安全方面也发生了重大变化。因此，现在的网站比以前复杂得多，并且通常需要更多的工程努力才能具有健壮性和可拓展性。
一个网站架构的最大的变化之一经常是并发性。从Web服务开始以来，并发级别一直在不断增长。一个流行网站同时服务数十万甚至数百万用户的情况并不罕见。十年前，并发的主要原因是慢客户端（slow clients）——具有ADSL或拨号连接的用户。如今，并发是由于移动客户端和较新的应用程序体系架构的组合引起的，这些体系结构通常基于持久连接，以支持客户端实时更新新闻、推文和朋友订阅源等。另一个因素是现代浏览器的行为改变——它可以打开四到六个与网站的同时连接，以提高页面加载速度。
为了说明慢客户端的问题，想象一个简单的基于Apache Web服务器，它产生一个相对较短的100 KB响应——一个带有文本或图像的网页。生成或健讼此页面只需要几分之一秒，但需要10秒才能将其传输到带宽为80 kbps（10KB/s）的客户端。从本质上讲，Web服务器会相对快都地提取100KB的内容，然后在释放连接之前，它将忙于将内容缓慢地（10秒）发送到客户端。假设有1000个同时连接的客户，他们呢请求了类似的内容。若每个客户端分配1MB的额外内存，则会产生1000 MB（约1 GB）的额外内存，专门用于为1000个用户端提供100 KB的内容。实际上，基于Apache的典型Web服务器通常为每个连接分配超过1 MB的额外内存，令人遗憾的是，数十kbps仍然是移动通信的有效速度。虽然在某种程度上通过增加操作系统内核socket缓冲区大小来改善向慢速客户端发送内懂的情况，但这不是解决该问题的一般办法，并且可能具有不良副作用。
为了避免建立新HTTP连接的延时，客户端与服务端保持连接（persistent connection），并发处理的问题更加明显，Web服务器为每个已连接的客户端分配一定数量的内存。
因此，为了处理与增长的受众相关的增加的工作量以及因此更高的并发水平——并且能够持续这样做——网站应该基于许多非常有效的构建块（building block）。硬件（CPU、内存、磁盘等）、网络能力、数据存储架构显然与Web服务器接受和处理客户端连接同等重要。因此，Web服务器应该能够随着并发连接和请求数量的增加而非线性地拓展。
Apache不合适吗？ Apache这款web服务器程序在很大程度上仍然主宰着互联网，它起源于20世纪90年代初。最初，它的架构与当时存在的操作系统和硬件相匹配，其中网站通常是运行单个Apache实例的独立物理服务器。2000年代初，轻松复制独立的Web服务器模型显然不足以满足不断增长的Web服务需求。尽管Apache为未来的开发提供了坚实的基础，但它的架构是为每个新连接生成自己的副本，这不适合网站的非线性可伸缩性。最终，Apache成为了一个通用的Web服务器，专注于拥有许多不同的功能，各种第三方拓展，以及几乎任何类型Web应用程序开发的普遍适用性。然后，没有任何代价地在单个软件中拥有如此丰富和通用的工具组合的缺点是可伸缩性较差，因为每个连接都会增加CPU和内存的使用量。
因此，当服务器硬件、操作系统和网络资源不再成为网站增加的主要限制时，全球的Web开发人员开始寻找更有效的运行Web服务器的方法。大约十年前，著名软件工程师Daniel Kegel宣称：Web服务器是时候同时处理一万个客户端的时候了，并预测了我们现在所谓互联网云服务的东西。Kegel的C10K清单激发了许多尝试来解决Web服务器优化问题，同时处理大量客户端，而nginx成为最成功的之一。
旨在解决10,000个同时连接的C10K问题，nginx在编写时考虑了不同的体系结构——一个更适合并发连接数和每秒请求数的非线性可伸缩性。nginx是基于事件的（event-based），并不遵循Apache为每个网页请求生成新进程或线程的风格，以实现即使负载增加，CPU和内存适用仍然可控。nginx现在可以在一台典型主机上处理数万个并发连接。
nginx首个版本发布时，作为静态内容（如HTML、CSS、JavaScript和图片）服务器与Apache一起部署，分担基于Apache的应用服务器的并发和延时。在开发过程中，nginx通过适用FastCGI，uSWGI或SCGI协议以及分布式内存对象缓存系统（如memcached）增加了与应用程序的集成，其他有用的功能也被开发出来，如具有负载均衡和缓存反向代理（reverse proxy）等等。这些附加功能使nginx成为有效的工具组合，可构建可拓展的Web基础架构。
2012年2月，Apache 2.4.x分支公开发布，尽管其最新版本添加了新的多处理核心模块，以及新的指向增强可伸缩性和性能的代理模块，现在谈论它与纯事件驱动的Web服务器谁在性能、并发和资源利用等方面更好还为时尚早。非常高兴能看到Apache应用服务器伸缩性能更好，不过，可能缓解在典型nginx加Apache的Web配置中仍然没解决的问题。
使用nginx有更多的优势吗？ 以高性能和高效率处理高并发始终是部署nginx的关键优势，但现在有更多有趣的好处。
在最近几年，Web架构师已经接受了将其应用程序基础设施与Web服务器解耦和分离的想法。然而，以前以LAMP（Linux，Apache，MySQL，PHP，Python或Perl）为基础的网站形式，现在可能不仅仅是一个基于LEMP的（E&amp;rsquo;代表&amp;rsquo;Engine x'）但是，越来越多的做法是将Web服务器推向基础设施的边缘，并以不同的方式围绕它集成相同或经过改进的应用程序和数据库工具集。
nginx很适合这些，因为它提供了方便处理并发、延迟，SSL，静态内容，压缩和缓存，连接和请求限制，甚至来自应用程序的HTTP媒体流所需的关键功能层到更有效的边缘Web服务器层，它还允许直接与memcached / Redis或其他“NoSQL”解决方案集成，以在为大量并发用户提供服务时提高性能。
nginx代码库是原创的，完全是用C编程语言从头开始编写的。 nginx已经移植到许多架构和操作系统，包括Linux，FreeBSD，Solaris，Mac OS X，AIX和Microsoft Windows。 nginx有自己的库，其标准模块除了zlib，PCRE和OpenSSL之外不会超出系统的C库，zlib，PCRE和OpenSSL可以选择从构建中排除，如果不需要或者由于潜在的许可证冲突。</description></item><item><title>Linux的TCP backlog如何工作</title><link>https://zenuo.github.io/posts/2018/11/18/linux%E7%9A%84tcp-backlog%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C/</link><pubDate>Sun, 18 Nov 2018 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2018/11/18/linux%E7%9A%84tcp-backlog%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C/</guid><description>本文翻译自How TCP backlog works in Linux。
当某个应用程序使用listen系统调用将一个socket置为LISTEN状态时，需要为这个socket设置参数backlog，该参数通常被描述为传入（incoming）连接队列的数量限制。
因为TCP使用三步握手（3-way handshake），在一个传入的连接在到达ESTABLISHED状态之前必须经过中间（intermediate）状态SYN RECEIVED，并且可由accept系统调用返回到应用程序（请参阅上面复制的TCP状态图）。这意味着TCP/IP堆栈有两个选项来实现LISTEN状态的socket的积压队列（backlog queue）：
使用大小由listen系统调用的backlog参数决定的单队列实现。当某个connection接收SYN分组时，它会发回SYN/ACK分组并将连接入列；当接收到相应的ACK分组时，连接将其状态改变为ESTABLISHED并且有资格切换到应用程序。也就是说，队列中包含两种不同状态——SYN RECEIVED和ESTABLISHED，只有后一种状态的connection才能通过accept系统调用返回给应用程序。
使用一个SYN队列（未完成的连接队列）和一个accept队列（已完成的连接队列）。状态SYN RECEIVED中的connection被添加到SYN队列中，并且当它们的状态变为ESTABLISHED时，即当接收到3次握手中的ACK分组时，移动到accept队列。顾名思义，accept系统调用然后只是为了消费（consume）来自accept队列的连接而实现。在这种情况下，listen系统调用的backlog参数确定accept队列的大小。
从历史上看，BSD派生的TCP实现使用第一种选项，意味着当达到最大backlog时，系统将不再发回SYN/ACK分组以响应SYN分组。通常，TCP实现只会丢弃SYN分组（而不是响应RST分组），以便客户端重试。这是W. Richard Stevens的经典教材TCP/IP详解 卷3的第14.5节listen Backlog Queue描述的内容。
请注意，Stevens实际上解释了BSD实现确实使用了两个单独的队列，但它们表现为单个队列，其固定的最大大小由backlog参数确定（但不一定完全等于），即BSD在逻辑上表现如第一个选项所述：
队列限制适用于[&amp;hellip;]不完整连接队列上的条目数和[&amp;hellip;]已完成连接队列[&amp;hellip;]上的条目数之和。
在Linux上，事情是不同的，如listen系统调用的手册页中所述：
Linux 2.2修改了TCP socket的backlog参数的行为。现在它指定了等待被accept的完全建立的套接字的队列长度，而不是未完成的连接请求的数量。可以在文件/proc/sys/net/ipv4/tcp_max_syn_backlog中设置未完成的socket队列的长度。
这意味着当前的Linux版本使用具有两个不同队列的第二个选项：具有由系统范围设置指定的大小的SYN队列和具有由应用程序指定的大小的accept队列。
现在有趣的问题是，如果接受队列已满并且需要将连接从SYN队列移动到接受队列，即当接收到3次握手的ACK分组时，这种实现如何表现。这种情况由net/ipv4/tcp_minisocks.c中的tcp_check_req函数处理，相关代码如下：
child = inet_csk(sk)-&amp;gt;icsk_af_ops-&amp;gt;syn_recv_sock(sk, skb, req, NULL); if (child == NULL) goto listen_overflow; 对于IPv4，第一行代码实际调用net/ipv4/tcp_ipv4.</description></item><item><title>浅谈Java对函数式编程的支持</title><link>https://zenuo.github.io/posts/2018/11/09/%E6%B5%85%E8%B0%88java%E5%AF%B9%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E7%9A%84%E6%94%AF%E6%8C%81/</link><pubDate>Fri, 09 Nov 2018 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2018/11/09/%E6%B5%85%E8%B0%88java%E5%AF%B9%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E7%9A%84%E6%94%AF%E6%8C%81/</guid><description>此篇文章主要基于对java.util.function包的javadoc翻译，谈谈Java对函数式编程的支持，亦有助于学习Stram API。
1 什么是函数式编程？ 在计算机科学中，函数式编程（Functional programing）是一种将计算（Computation）视为数学函数的评估，避免改变状态（changing-state）和可变数据（mutable data）的编程范式（一种构建计算机程序结构和元素的方式）。
In computer science, functional programming is a programming paradigm—a style of building the structure and elements of computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. 摘自维基百科
2 java.util.function包 Java自1.8添加java.util.function包，以支持函数式编程；其将计算抽象为函数式接口（Functional interface），为lambda表达式（lambda expressions）和方法引用（method references）提供了目标类型。每一个函数式接口含有单个抽象方法，称为该函数式接口的函数式方法（functional method），lambda表达式的参数和返回类型与之匹配或适应。在多种上下文中，函数式接口可提供一个目标类型，如赋值、方法调用和转型上下文：</description></item><item><title>Timsort 你从未听说过的最快的排序算法</title><link>https://zenuo.github.io/posts/2018/08/16/timsort-%E4%BD%A0%E4%BB%8E%E6%9C%AA%E5%90%AC%E8%AF%B4%E8%BF%87%E7%9A%84%E6%9C%80%E5%BF%AB%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</link><pubDate>Thu, 16 Aug 2018 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2018/08/16/timsort-%E4%BD%A0%E4%BB%8E%E6%9C%AA%E5%90%AC%E8%AF%B4%E8%BF%87%E7%9A%84%E6%9C%80%E5%BF%AB%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</guid><description>本文翻译自Timsort — the fastest sorting algorithm you’ve never heard of，如侵必删。
Timsort: 一个非常快速的，时间复杂度O(n log n)，为真实世界构建的稳定排序算法——而不是学术界。
Timsort是一个对于真实世界数据具有高效率的、不是在学术实验室中发表的排序算法，由Tim Peters在2001年为Python编程语言创造。它试图首先分析需要排序的列表，然后基于分析选择一种方法。
从发表至今，该算法已经被用作Python, Java, Android(TM)和GNU Octave用作默认排序算法。
Timsort的大O标记法(big O notation)是O(n log n).学习大O标记法，请移步至此。
Timsort的排序时间与归并排序相同，后者比您可能知道的其他大多数排序算法要快。正如你很快将要看到的，Timsort实际上使用了插入排序和归并排序。
Peters将Timsort设计为使用真实世界的数据中已经有序的元素。它将这些已经有序的元素称作“自然的运行(natural runs)”。它迭代整个数据，将元素收集到多个run中，同时将多个run合并到一个。
列表长度小于64 若列表尝试排序其内部少于64个元素时，Timsort将会执行一个插入排序。
插入排序是一种简单的排序，对于小型列表效率最高。在较大的列表中确实比较慢，但在小型列表中却非常快。插入排序的概念如下：
逐个查看元素 通过将元素插入正确的位置来构建排序列表 这是一个跟踪列表，显示了[34, 10, 64, 51, 32, 21]如何进行插入排序：
在这个例子中，我们将一个新排序的元素插入一个新的子数组，该子数组从数组的开头开始。
这是一个显示插入排序的GIF：
关于run的细节 如果列表大于64个元素，则算法将首先通过列表查找严格增加或减少的部分。如果某个部分正在减少，它将该部分反转。因此，如果运行正在减少，它将看起来像这样（运行以粗体显示）：
若不减少，则看起来像这样：
minrun是基于数组大小确定的。该算法选择它，以便大多数在随机数组中运行的长度为minrun。当运行次数等于或略小于2的幂时，合并2个数组会更高效。Timsort选择minrun来保持使minrun的长度不大于2的幂。该算法选择范围为32到64（包括32和64）的minrun，使得原始数组的长度除以minrun时等于或略小于2的幂。
如果某个run的长度小于minrun，则计算两者差值，使用此新数字，您可以在run的头部获取许多元素并执行插入排序以创建一个新的run。</description></item><item><title>什么是数学-Richard-Courant</title><link>https://zenuo.github.io/posts/2018/06/24/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E5%AD%A6-richard-courant/</link><pubDate>Sun, 24 Jun 2018 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2018/06/24/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E5%AD%A6-richard-courant/</guid><description>摘自什么是数学：对思想和方法的基本研究
**数学，作为人类思维的表达形式，反映了人们积极进取的意志、缜密周详的推理以及对完美境界的追求。**它的基本要素是：逻辑和直观、分析和构作、一般性和个别性。虽然不同的传统可以强调不同的侧面，然而正是这些互相对立的力量的相互作用以及它们综合起来的努力才构成了数学科学的生命、用途和它的崇高价值。
毫无疑问，一切数学的发展在心理上都或多或少地是基于实际的。但是理论一旦在实际的需要中出现，就不可避免地会使它自身获得发展的动力，并超越出直接实用的局限。这种从应用科学到理论科学的发展趋势，不仅常见于古代历史中，而且在工程师和物理学家为近代数学不断作出的许多贡献中更是屡见不鲜。
有记载的数学起源于东方。大约在公元前两千年，巴比伦人就搜集了极其丰富的资料，这些资料今天看来应属于初等代数的范围。至于数学作为现代意义的一门科学，则是迟至公元前5至公元前4世纪才在希腊出现的。东方和希腊之间的接触不断增多（始于波斯帝国时期，至亚历山大远征时期则达到高峰），使希腊人得以熟悉巴比伦人在数学和天文学方面的成就，数学很快就被加入到风行于希腊城邦的哲学讨论之中。因而希腊的思想家逐渐意识到，在连续、运动、无限大这些概念中，以及在用已知单位去度量任意一个量的问题中，数学都存在着固有的极大困难。面对这个挑战，经过了一番不屈不挠的努力，产生了欧多克斯（Eudoxus）的几何连续统理论，这个成果是唯一能和两千多年后的现代无理数理论相媲美的。数学中这种公理演绎的趋向起源于欧多克斯时代，又在欧几里得（Euclid）的“原本”中得以成熟。
虽然希腊数学的理论化和公理化的倾向一直是它的一个重要特点，并且曾经产生过巨大的影响。但是，对这一点我们不能过分强调，因为在古代数学中，应用以及同物理现实的联系恰恰起了同样重要的作用，而且那时候人们宁愿采用不像欧几里得那样严密的表达方式。
由于较早地发现了与“不可公度”的量有关的这些困难，使希腊人没能发展早已为东方所掌握的数字计算的技术。相反，他们却迫使自己钻进了纯粹公理几何的丛林之中。于是科学史上出现了一个奇怪的曲折。这或许意味着人类丧失了一个很好的时机。几乎两千年来，希腊几何的传统力量推迟了必然会发生的数的概念和代数运算的进步，而它们后来构成了近代科学的基础。
经过了一段缓慢的准备，到17世纪，随着解析几何与微积分的发展，数学和科学的革命也开始蓬勃发展起来。虽然希腊的几何学仍然占有重要的地位，但是，希腊人关于公理体系和系统推演的思想在17世纪和18世纪不复出现。从一些清清楚楚的定义和没有矛盾的“明显”公理出发，进行准确的逻辑推理，这对于数学科学的新的开拓者来说似乎是无关紧要的。**通过毫无拘束的直观猜想和令人信服的推理，再加上荒谬的神秘论以及对形式推理的超人力量的盲目相信，他们征服了一个蕴藏着无限财富的数学世界。**但是后来，大发展引起的狂热逐渐让位于一种自我控制的批判精神。到了19世纪，由于数学本身需要巩固已有成果，而且人们也希望把它推向更高阶段时不致发生问题（这是受到法国大革命的影响），就不得不回过头来重新审查这新的数学基础，特别是微积分及其赖以建立的极限概念。因此19世纪不仅成为一个新的发展时期，而且也以成功地返回到那种准确而严谨的证明为其特征。在这方面它甚至胜过了希腊科学的典范。于是，钟摆又一次向纯粹性和抽象性的一侧摆去。目前我们似乎仍然处于这个时期。**但是人们可以期望，在纯粹数学和具有活力的应用之间产生了这种不幸分离（可能在批判性的审查时期，这是不可避免的）之后，随之而来的应是一个紧密结合的时代。**这种重新获得的内在力量，更主要的是由于理解更加明晰而达到认识上的极大简化，将使得今天有可能在不忽略应用的情况下来掌握数学理论。再一次在纯数学和应用科学之间建立起有机的结合，在抽象的共性和色彩缤纷的个性之间建立起牢固的平衡，这或许就是不久的将来数学上的首要任务。
这里不是对数学进行详细的哲学或心理学的分析的地方。但有几点应当强调一下。目前过分强调数学的公理演绎特点的风气，似乎有盛行起来的危险。事实上，那种创造发明的要素，那种起指导和推动作用的直观要素，虽然常常不能用简单的哲学公式来表述，但是它们却是任何数学成就的核心，即使在最抽象的领域里也是如此。如果说完善的演绎形式是目标，那么直观和构作至少也是一种动力。**有一种观点对科学本身是严重的威胁，它断言数学不是别的东西，而只是从定义和公理推导出来的一组结论，而这些定义和命题除了必须不矛盾之外，可以由数学家根据他们的意志随意创造。**如果这个说法是正确的话，数学将不会吸引任何有理智的人。它将成为定义、规则和演绎法的游戏，既没有动力也没有目标。认为灵感能创造出有意义的公理体系的看法，是骗人的似是而非的真理。只有在以达到有机整体为目标的前提下，以及在内在需要的引导下，自由的思维才能作出有科学价值的成果来。
尽管逻辑分析的思辨趋势并不代表全部数学，但它却使我们对数学事实和它们相互间的依赖关系有更深刻的理解，以及对数学中的主要概念有更深刻的理解，并由此发展了可作为一般科学态度的典范的近代数学观点。
不论我们持什么样的哲学观点，就科学观察的目的来说，对一个对象的认识，完全表现在它与认识者（或仪器）的所有可能关系之中。当然仅仅是感觉并不能构成知识和见解，必须要与某些基本的实体即“自在之物”相适应、相印证，所谓“自在之物”并不是物体观察的直接对象，而是属于形而上学的。然而，对于科学方法来说，重要的是应放弃带有形而上学性质的因素，而去考虑那些可观测的事实，把它们作为概念和构作的最终根源。放弃对“自在之物”的领悟，对“终极真理”的认识以及关于世界的最终本质的阐明，这对于质朴的热诚者来说，可能会带来一种心理上的痛苦，但事实上它却是近代思想上最有成效的一种转变。
物理学上所取得的一些最伟大的成就，正是由于敢于坚持“消除形而上学”这个原则的结果。当爱因斯坦（A. Einstein）试图把“在不同地方同时发生的事件”这一概念归结为可观测的现象时，当他揭露出，认为上述概念必须有它自身的科学意义的信念只是形而上学的偏见时，他已发现了他的相对论的关键所在。当玻尔（N. Bohr）和他的学生们指出，任何物理观测必然伴随着观测工具对被观测对象的影响这个事实时，问题变得很清楚，在物理上，同时准确地确定一个粒子的位置和速度是不可能的。这个发现的深远意义体现在为每个物理学家所熟悉的近代量子力学的理论中。在十九世纪流行着一种概念，认为机械力和粒子在空间中的运动是自在之物，而电、光和磁都应当归结为力学现象或者作为力学现象来“解释”，正如以前处理“热”的方法那样。人们曾经假设过“以太”，作为一种假设性的媒介物，把它用于那些对我们来说不能完全加以解释的运动中，例如光或电。后来人们才慢慢地认识到以太是肯定无法观测到的，它属于形而上学，而不属于物理学。于是乎，在某些方面感到忧虑，而在另一些方面又感到安慰的心情下，关于光和电的力学解释连同以太最后一齐都被放弃了。
在数学中有些情况与此相类似，甚至更为突出。世世代代以来，数学家一直把他们研究的对象，例如数、点等等，看成实实在在的自在之物。但是，准确地描述这些实体的种种努力总是被这些实体自身绐否定了。从而十九世纪的数学家逐渐开始懂得，要问当作实体的这些对象究竟是什么，这是没有意义的，即使有的话也不可能在数学范围内得到解决。所有适合它们的论断都不涉及这些实体的现实，而只说明数学上“不加定义的对象”之间的相互关系以及它们所遵循的运算法则。至于点、线、数，“实际上”是什么，这不可能也不需要在数学科学中加以讨论。“可验证”的事实只是结构和关系：两点决定一直线，一些数按照某些规则组成其他一些数，等等。基本的数学概念必须抽象化，这一见解是近代公理化发展中最重要和最丰富的成果之一。
幸运的是，创造性的思维不顾某些教条的哲学信仰而继续发展着，而如果思维屈从于这种信仰就会阻碍出现建设性的成就。不论对专家来说，还是对普通人来说，唯一能回答“什么是数学”这个问题的，不是哲学而是数学本身中的活生生的经验。</description></item><item><title>使用构造方法注入依赖</title><link>https://zenuo.github.io/posts/2018/06/14/%E4%BD%BF%E7%94%A8%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95%E6%B3%A8%E5%85%A5%E4%BE%9D%E8%B5%96/</link><pubDate>Thu, 14 Jun 2018 19:23:13 +0800</pubDate><guid>https://zenuo.github.io/posts/2018/06/14/%E4%BD%BF%E7%94%A8%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95%E6%B3%A8%E5%85%A5%E4%BE%9D%E8%B5%96/</guid><description>1 什么是依赖注入 在软件工程中，依赖注入是一种对象提供另一对象的依赖性的技术。依赖关系是可以使用的对象（服务）。注入是将依赖关系传递给将使用它的依赖对象（客户端）。
2 为什么使用构造方法注入 使用Spring提供的@Autowired注解，我们可以通过标记构造方法(constructor)、域(field)、setter方法和配置方法(config methods)来实现依赖注入。我们使用较多的是标记域的方式，这使得客户端可以创建该类的不合法的实例，不利于问题排查和测试，这一点在Oliver Gierke的Why field injection is evil的文章中已有说明。
3 如何使用构造方法注入 结合Lombok注解使用构造方法注入可简化代码：
@Service @Slf4j @RequiredArgsConstructor(onConstructor = @__(@Autowired)) //注意点1 public class OssSyncService { private final @NonNull //注意点2 OssSyncObjectRepository ossSyncObjectRepository; private final @NonNull OssSyncInfoRepository ossSyncInfoRepository; private final @NonNull S3Config s3Config; //其余省略 } 注意点1-类前标注@RequiredArgsConstructor(onConstructor = @__(@Autowired)) 注意点2-依赖的Bean使用private final修饰符和@NonNull注解 4 参考 http://olivergierke.</description></item></channel></rss>